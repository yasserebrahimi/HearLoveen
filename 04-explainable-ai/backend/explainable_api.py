"""
HearLoveen - Explainable AI Module
===================================

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ ØªÙˆØ¶ÛŒØ­Ø§Øª Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…Ø§Øª AI Ø¨Ù‡ Ù¾Ø²Ø´Ú©Ø§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
Ø§Ø² SHAP (SHapley Additive exPlanations) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

Author: Yasser Ebrahimi Fard
Date: November 2025
"""

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple
import torch
import torch.nn as nn

# ===========================
# 1. PRONUNCIATION EXPLAINER
# ===========================

class ExplainablePronunciationScorer:
    """
    ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡Ù†Ø¯Ù‡ Ù†Ù…Ø±Ø§Øª ØªÙ„ÙØ¸ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SHAP
    """
    
    def __init__(self, model, feature_names):
        """
        Args:
            model: Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ (PyTorch ÛŒØ§ sklearn)
            feature_names: Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ ['MFCC1', 'MFCC2', ...])
        """
        self.model = model
        self.feature_names = feature_names
        self.explainer = None
        
    def initialize_explainer(self, background_data):
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ SHAP explainer Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        
        Args:
            background_data: Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
        """
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ PyTorch
        if isinstance(self.model, nn.Module):
            self.explainer = shap.DeepExplainer(self.model, background_data)
        else:
            # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ sklearn
            self.explainer = shap.KernelExplainer(
                self.model.predict, 
                background_data
            )
        print("âœ… SHAP Explainer initialized")
    
    def explain_prediction(self, audio_features):
        """
        ØªÙˆØ¶ÛŒØ­ ÛŒÚ© Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø®Ø§Øµ
        
        Args:
            audio_features: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ (41-dim MFCC+)
            
        Returns:
            Dict Ø­Ø§ÙˆÛŒ ØªÙˆØ¶ÛŒØ­Ø§Øª
        """
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        score = self.model.predict(audio_features.reshape(1, -1))[0]
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ SHAP values
        shap_values = self.explainer.shap_values(audio_features.reshape(1, -1))
        
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù‡Ù…ÛŒØª
        feature_importance = list(zip(
            self.feature_names,
            shap_values[0],
            audio_features
        ))
        feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)
        
        # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­Ø§Øª Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù…
        explanation = self._generate_human_explanation(
            score, 
            feature_importance[:5]  # top 5 features
        )
        
        return {
            'pronunciation_score': float(score),
            'shap_values': shap_values[0].tolist(),
            'feature_importance': feature_importance,
            'human_explanation': explanation,
            'actionable_recommendations': self._generate_recommendations(
                feature_importance[:5]
            )
        }
    
    def _generate_human_explanation(
        self, 
        score: float, 
        top_features: List[Tuple]
    ) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡
        """
        explanation = f"Ù†Ù…Ø±Ù‡ ØªÙ„ÙØ¸: {score:.1f}/100\n\n"
        
        if score >= 80:
            explanation += "âœ… ØªÙ„ÙØ¸ Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨ Ø§Ø³Øª!\n\n"
        elif score >= 60:
            explanation += "âš ï¸ ØªÙ„ÙØ¸ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ØŒ Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\n\n"
        else:
            explanation += "âŒ ØªÙ„ÙØ¸ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ…Ø±ÛŒÙ† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯.\n\n"
        
        explanation += "Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø§ØµÙ„ÛŒ:\n"
        
        for feature_name, shap_value, feature_value in top_features:
            impact = "Ù…Ø«Ø¨Øª âœ…" if shap_value > 0 else "Ù…Ù†ÙÛŒ âŒ"
            
            # ØªØ±Ø¬Ù…Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÙ†ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡
            simple_explanation = self._translate_feature(feature_name, feature_value)
            
            explanation += f"  â€¢ {simple_explanation} (ØªØ£Ø«ÛŒØ± {impact})\n"
        
        return explanation
    
    def _translate_feature(self, feature_name: str, value: float) -> str:
        """
        ØªØ±Ø¬Ù…Ù‡ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒ ÙÙ†ÛŒ Ø¨Ù‡ ØªÙˆØ¶ÛŒØ­ Ø³Ø§Ø¯Ù‡
        """
        translations = {
            'spectral_centroid': 'Ù…Ø±Ú©Ø² Ø·ÛŒÙ ØµÙˆØª',
            'spectral_flux': 'ØªØºÛŒÛŒØ±Ø§Øª ØµØ¯Ø§',
            'mfcc_1': 'Ø®ØµÙˆØµÛŒØª Ø§ÙˆÙ„ ØµØ¯Ø§ (Ø±Ù†Ú¯ ØµØ¯Ø§)',
            'mfcc_2': 'Ø®ØµÙˆØµÛŒØª Ø¯ÙˆÙ… ØµØ¯Ø§',
            'pitch_mean': 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²ÛŒØ± Ùˆ Ø¨Ù…ÛŒ ØµØ¯Ø§',
            'pitch_std': 'ØªØºÛŒÛŒØ±Ø§Øª Ø²ÛŒØ± Ùˆ Ø¨Ù…ÛŒ',
            'energy': 'Ø§Ù†Ø±Ú˜ÛŒ ØµØ¯Ø§',
            'zcr': 'Ù†Ø±Ø® Ø¹Ø¨ÙˆØ± Ø§Ø² ØµÙØ±',
            'formant_f1': 'ÙÙˆØ±Ù…Ø§Ù†Øª Ø§ÙˆÙ„ (Ù…ÙˆÙ‚Ø¹ÛŒØª Ø²Ø¨Ø§Ù†)',
            'formant_f2': 'ÙÙˆØ±Ù…Ø§Ù†Øª Ø¯ÙˆÙ… (Ø´Ú©Ù„ Ø¯Ù‡Ø§Ù†)',
        }
        
        simple_name = translations.get(feature_name, feature_name)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø¯Ø§Ø±
        if 'mfcc' in feature_name.lower():
            if abs(value) > 2:
                return f"{simple_name}: Ù…Ù‚Ø¯Ø§Ø± ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ"
            else:
                return f"{simple_name}: Ù…Ù‚Ø¯Ø§Ø± Ø¹Ø§Ø¯ÛŒ"
        elif 'pitch' in feature_name.lower():
            if value < 200:
                return f"{simple_name}: Ù¾Ø§ÛŒÛŒÙ† (Ø²ÛŒØ± Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ¯Ú©)"
            elif value > 500:
                return f"{simple_name}: Ø¨Ø§Ù„Ø§ (Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø§Ù†ØªØ¸Ø§Ø±)"
            else:
                return f"{simple_name}: Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø·Ø¨ÛŒØ¹ÛŒ"
        elif 'energy' in feature_name.lower():
            if value < 0.01:
                return f"{simple_name}: Ø¶Ø¹ÛŒÙ (Ú©ÙˆØ¯Ú© Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¢Ø±Ø§Ù… ØµØ­Ø¨Øª Ú©Ù†Ø¯)"
            else:
                return f"{simple_name}: Ù…Ù†Ø§Ø³Ø¨"
        
        return simple_name
    
    def _generate_recommendations(self, top_features: List[Tuple]) -> List[str]:
        """
        ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†Ú¯Ø±
        """
        recommendations = []
        
        for feature_name, shap_value, feature_value in top_features:
            if shap_value < -0.5:  # ØªØ£Ø«ÛŒØ± Ù…Ù†ÙÛŒ Ù‚ÙˆÛŒ
                
                if 'formant' in feature_name.lower():
                    recommendations.append({
                        'issue': 'Ù…ÙˆÙ‚Ø¹ÛŒØª Ø§Ù†Ø¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ú¯ÙØªØ§Ø±ÛŒ',
                        'recommendation': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø²Ø¨Ø§Ù† Ùˆ Ø´Ú©Ù„ Ø¯Ù‡Ø§Ù†',
                        'exercises': [
                            'Ø¢ÛŒÙ†Ù‡â€ŒØ§ÛŒ ØªÙ…Ø±ÛŒÙ† Ú©Ù†ÛŒØ¯',
                            'ØªØµØ§ÙˆÛŒØ± Ù…Ø¯Ù„ ØµØ­ÛŒØ­ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡ÛŒØ¯',
                            'Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù„Ù…Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯'
                        ],
                        'priority': 'high'
                    })
                
                elif 'pitch' in feature_name.lower():
                    recommendations.append({
                        'issue': 'Ú©Ù†ØªØ±Ù„ pitch (Ø²ÛŒØ± Ùˆ Ø¨Ù…ÛŒ)',
                        'recommendation': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª ØªÙ† Ùˆ Ø¢ÙˆØ§Ø²',
                        'exercises': [
                            'Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø§ ØªØºÛŒÛŒØ± pitch',
                            'ØªÙ‚Ù„ÛŒØ¯ ØµØ¯Ø§Ù‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒÛŒÙ†',
                            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± visual pitch'
                        ],
                        'priority': 'medium'
                    })
                
                elif 'energy' in feature_name.lower():
                    recommendations.append({
                        'issue': 'Ø§Ù†Ø±Ú˜ÛŒ ØµØ¯Ø§ Ø¶Ø¹ÛŒÙ',
                        'recommendation': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª ØªÙ†ÙØ³ÛŒ Ùˆ ØªÙ‚ÙˆÛŒØª ØµØ¯Ø§',
                        'exercises': [
                            'ØªÙ†ÙØ³ Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø¯ÛŒØ§ÙØ±Ø§Ú¯Ù…',
                            'ØµØ­Ø¨Øª Ø¨Ø§ ØµØ¯Ø§ÛŒ Ø¨Ù„Ù†Ø¯ØªØ±',
                            'ØªÙ…Ø±ÛŒÙ† projection'
                        ],
                        'priority': 'medium'
                    })
                
                elif 'spectral' in feature_name.lower():
                    recommendations.append({
                        'issue': 'ÙˆØ¶ÙˆØ­ ØµØ¯Ø§',
                        'recommendation': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª articulation',
                        'exercises': [
                            'Ø­Ø±Ú©Ø§Øª Ø¯Ù‚ÛŒÙ‚ Ù„Ø¨ Ùˆ Ø²Ø¨Ø§Ù†',
                            'ØªÙ…Ø±ÛŒÙ† Ù‡Ø¬Ø§ Ø¨Ù‡ Ù‡Ø¬Ø§',
                            'slow motion speech'
                        ],
                        'priority': 'high'
                    })
        
        # Ø§Ú¯Ø± ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ Ù†Ø¨ÙˆØ¯ØŒ ÛŒÚ© ØªÙˆØµÛŒÙ‡ Ø¹Ù…ÙˆÙ…ÛŒ
        if not recommendations:
            recommendations.append({
                'issue': 'Ø§Ø¯Ø§Ù…Ù‡ ØªÙ…Ø±ÛŒÙ†Ø§Øª ÙØ¹Ù„ÛŒ',
                'recommendation': 'Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ Ø§Ø³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯',
                'exercises': [
                    'Ø­ÙØ¸ ØªÙ…Ø±ÛŒÙ†Ø§Øª Ù…Ù†Ø¸Ù…',
                    'Ø§ÙØ²Ø§ÛŒØ´ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø³Ø®ØªÛŒ',
                    'ØªÙ…Ø±ÛŒÙ† Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù'
                ],
                'priority': 'low'
            })
        
        return recommendations

# ===========================
# 2. EMOTION EXPLAINER
# ===========================

class ExplainableEmotionDetector:
    """
    ØªÙˆØ¶ÛŒØ­ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª
    """
    
    def __init__(self, model):
        self.model = model
        self.emotion_labels = [
            'Happy', 'Sad', 'Angry', 'Fearful', 
            'Neutral', 'Surprised', 'Disgusted'
        ]
    
    def explain_emotion(self, audio_features, iot_data=None):
        """
        ØªÙˆØ¶ÛŒØ­ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        
        Args:
            audio_features: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
            iot_data: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ IoT (Ø¶Ø±Ø¨Ø§Ù† Ù‚Ù„Ø¨ØŒ ...)
            
        Returns:
            Dict Ø­Ø§ÙˆÛŒ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø­Ø³Ø§Ø³ÛŒ
        """
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        emotion_probs = self.model.predict_proba(audio_features)[0]
        predicted_emotion = self.emotion_labels[np.argmax(emotion_probs)]
        confidence = np.max(emotion_probs)
        
        # ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
        prosodic_analysis = self._analyze_prosody(audio_features)
        
        # ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ IoT (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        iot_analysis = None
        if iot_data is not None:
            iot_analysis = self._analyze_iot_data(iot_data)
        
        # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­Ø§Øª
        explanation = self._generate_emotion_explanation(
            predicted_emotion,
            confidence,
            prosodic_analysis,
            iot_analysis
        )
        
        return {
            'predicted_emotion': predicted_emotion,
            'confidence': float(confidence),
            'all_probabilities': {
                label: float(prob) 
                for label, prob in zip(self.emotion_labels, emotion_probs)
            },
            'prosodic_analysis': prosodic_analysis,
            'iot_analysis': iot_analysis,
            'explanation': explanation,
            'recommendations': self._generate_emotion_recommendations(
                predicted_emotion,
                prosodic_analysis,
                iot_analysis
            )
        }
    
    def _analyze_prosody(self, features):
        """ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù‡Ù†Ú¯ÛŒÙ† Ú¯ÙØªØ§Ø±"""
        # ÙØ±Ø¶: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø´Ø§Ù…Ù„ pitch, energy, duration
        return {
            'pitch_level': 'high' if features[0] > 300 else 'normal',
            'energy_level': 'high' if features[1] > 0.5 else 'low',
            'speech_rate': 'fast' if features[2] < 0.1 else 'normal'
        }
    
    def _analyze_iot_data(self, iot_data):
        """ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ø³ÙˆØ±"""
        analysis = {}
        
        if 'heart_rate' in iot_data:
            hr = iot_data['heart_rate']
            if hr > 100:
                analysis['stress_level'] = 'high'
                analysis['stress_indicator'] = 'âš ï¸ Ø¶Ø±Ø¨Ø§Ù† Ù‚Ù„Ø¨ Ø¨Ø§Ù„Ø§'
            else:
                analysis['stress_level'] = 'normal'
                analysis['stress_indicator'] = 'âœ… Ø¶Ø±Ø¨Ø§Ù† Ù‚Ù„Ø¨ Ø¹Ø§Ø¯ÛŒ'
        
        if 'noise_level' in iot_data:
            noise = iot_data['noise_level']
            if noise > 60:
                analysis['environment'] = 'noisy'
                analysis['environment_note'] = 'âš ï¸ Ù…Ø­ÛŒØ· Ù¾Ø±Ø³Ø±ÙˆØµØ¯Ø§'
            else:
                analysis['environment'] = 'quiet'
                analysis['environment_note'] = 'âœ… Ù…Ø­ÛŒØ· Ø¢Ø±Ø§Ù…'
        
        return analysis
    
    def _generate_emotion_explanation(
        self, 
        emotion, 
        confidence, 
        prosody, 
        iot
    ):
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØ¶ÛŒØ­ Ø§Ø­Ø³Ø§Ø³ÛŒ"""
        
        explanation = f"Ø§Ø­Ø³Ø§Ø³ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: {emotion} "
        explanation += f"(Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence*100:.1f}%)\n\n"
        
        # ØªÙˆØ¶ÛŒØ­ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
        explanation += "Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§:\n"
        explanation += f"  â€¢ Ø³Ø·Ø­ ØµØ¯Ø§: {prosody['pitch_level']}\n"
        explanation += f"  â€¢ Ø§Ù†Ø±Ú˜ÛŒ: {prosody['energy_level']}\n"
        explanation += f"  â€¢ Ø³Ø±Ø¹Øª Ú¯ÙØªØ§Ø±: {prosody['speech_rate']}\n\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ IoT
        if iot:
            explanation += "Ø¯Ø§Ø¯Ù‡Ù‡Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ:\n"
            if 'stress_indicator' in iot:
                explanation += f"  â€¢ {iot['stress_indicator']}\n"
            if 'environment_note' in iot:
                explanation += f"  â€¢ {iot['environment_note']}\n"
        
        return explanation
    
    def _generate_emotion_recommendations(self, emotion, prosody, iot):
        """ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        
        recommendations = []
        
        if emotion in ['Sad', 'Frustrated', 'Angry']:
            recommendations.append({
                'action': 'Ø§Ø³ØªØ±Ø§Ø­Øª',
                'reason': 'Ú©ÙˆØ¯Ú© Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®Ø³ØªÙ‡ ÛŒØ§ Ù†Ø§Ø§Ù…ÛŒØ¯ Ø¨Ø§Ø´Ø¯',
                'suggestion': 'Ø§Ø³ØªØ±Ø§Ø­Øª 10 Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¯Ø§Ù…Ù‡'
            })
        
        if iot and iot.get('stress_level') == 'high':
            recommendations.append({
                'action': 'Ú©Ø§Ù‡Ø´ Ø§Ø³ØªØ±Ø³',
                'reason': 'Ø¶Ø±Ø¨Ø§Ù† Ù‚Ù„Ø¨ Ø¨Ø§Ù„Ø§ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø§Ø³ØªØ±Ø³ Ø§Ø³Øª',
                'suggestion': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª ØªÙ†ÙØ³ÛŒ ÛŒØ§ Ø¨Ø§Ø²ÛŒ Ø¢Ø±Ø§Ù…Ø´â€ŒØ¨Ø®Ø´'
            })
        
        if iot and iot.get('environment') == 'noisy':
            recommendations.append({
                'action': 'Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø­ÛŒØ·',
                'reason': 'Ø³Ø±ÙˆØµØ¯Ø§ÛŒ Ù…Ø­ÛŒØ· ØªÙ…Ø±Ú©Ø² Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯',
                'suggestion': 'Ø¨Ù‡ Ù…Ø­ÛŒØ· Ø¢Ø±Ø§Ù…â€ŒØªØ±ÛŒ Ø¨Ø±ÙˆÛŒØ¯ ÛŒØ§ Ø³Ø±ÙˆØµØ¯Ø§ Ø±Ø§ Ú©Ù… Ú©Ù†ÛŒØ¯'
            })
        
        if emotion == 'Happy' and prosody['energy_level'] == 'high':
            recommendations.append({
                'action': 'Ø§Ø¯Ø§Ù…Ù‡ ØªÙ…Ø±ÛŒÙ†',
                'reason': 'Ú©ÙˆØ¯Ú© Ø§Ù†Ú¯ÛŒØ²Ù‡ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø³Øª',
                'suggestion': 'Ø§ÛŒÙ† Ø²Ù…Ø§Ù† Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø±ÛŒÙ†Ø§Øª Ú†Ø§Ù„Ø´â€ŒØ¨Ø±Ø§Ù†Ú¯ÛŒØ² Ø§Ø³Øª'
            })
        
        return recommendations

# ===========================
# 3. DASHBOARD GENERATOR
# ===========================

def generate_therapist_dashboard(child_id, date_range):
    """
    ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†Ú¯Ø± Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„
    """
    # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙØ±Ø¶ÛŒ Ø§Ø³Øª Ùˆ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ backend Ù…ØªØµÙ„ Ø´ÙˆØ¯
    
    dashboard_data = {
        'child_info': {
            'id': child_id,
            'name': '[ANONYMIZED]',
            'age': 8,
            'hearing_loss': 'Moderate'
        },
        'summary': {
            'total_sessions': 45,
            'avg_pronunciation_score': 72.5,
            'improvement_rate': '+15%',
            'current_emotion': 'Happy',
            'engagement_level': 'High'
        },
        'explanations': [],
        'recommendations': []
    }
    
    return dashboard_data

# ===========================
# 4. API ENDPOINT
# ===========================

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="HearLoveen Explainable AI API")

class AudioAnalysisRequest(BaseModel):
    audio_features: List[float]
    phoneme: str
    child_id: str

@app.post("/api/explain/pronunciation")
async def explain_pronunciation(request: AudioAnalysisRequest):
    """
    API endpoint Ø¨Ø±Ø§ÛŒ ØªÙˆØ¶ÛŒØ­ Ù†Ù…Ø±Ù‡ ØªÙ„ÙØ¸
    """
    try:
        # Load model (Ø¯Ø± production Ø§Ø² cache Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯)
        # model = load_pronunciation_model()
        
        # Initialize explainer
        # explainer = ExplainablePronunciationScorer(model, feature_names)
        
        # Explain
        # result = explainer.explain_prediction(np.array(request.audio_features))
        
        # Ø¨Ø±Ø§ÛŒ demo:
        result = {
            'pronunciation_score': 75.0,
            'human_explanation': 'ØªÙ„ÙØ¸ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ØŒ Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØª Ø²Ø¨Ø§Ù† Ø¯Ø§Ø±Ø¯.',
            'actionable_recommendations': [
                {
                    'issue': 'Ù…ÙˆÙ‚Ø¹ÛŒØª Ø²Ø¨Ø§Ù†',
                    'recommendation': 'ØªÙ…Ø±ÛŒÙ†Ø§Øª Ø¢ÛŒÙ†Ù‡â€ŒØ§ÛŒ',
                    'priority': 'high'
                }
            ]
        }
        
        return result
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/dashboard/therapist/{child_id}")
async def get_therapist_dashboard(child_id: str):
    """
    Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†Ú¯Ø±
    """
    try:
        dashboard = generate_therapist_dashboard(child_id, date_range='last_30_days')
        return dashboard
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ===========================
# MAIN
# ===========================

if __name__ == "__main__":
    print("ğŸš€ HearLoveen Explainable AI Module")
    print("="*60)
    print("âœ… SHAP-based explanations")
    print("âœ… Human-readable output")
    print("âœ… Actionable recommendations")
    print("âœ… Therapist dashboard")
    print("="*60)
    
    # Run API server
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
